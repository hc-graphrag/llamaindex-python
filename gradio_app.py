import os
import asyncio
import logging
from typing import Optional, Tuple
import gradio as gr

from llama_index.llms.anthropic import Anthropic
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.core import Settings
from llama_index.core.node_parser import SentenceSplitter

from src.graphrag_anthropic_llamaindex.config_manager import load_config
from src.graphrag_anthropic_llamaindex.vector_store_manager import get_vector_store
from src.graphrag_anthropic_llamaindex.document_processor import add_documents
from src.graphrag_anthropic_llamaindex.search_processor import search_index
from src.graphrag_anthropic_llamaindex.file_filter import FileFilter

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class GraphRAGApp:
    def __init__(self):
        self.config = None
        self.llm_params = {}
        self.vector_stores = {}
        self.file_filter = None
        self.is_initialized = False
    
    def initialize_config(self, config_path: str = "config.yaml") -> str:
        try:
            self.config = load_config(config_path)
            if not self.config:
                return "âŒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ"
            
            # Initialize Anthropic settings
            anthropic_config = self.config.get("anthropic", {})
            if not anthropic_config.get("api_key"):
                return "âŒ Anthropic APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
                
            os.environ["ANTHROPIC_API_KEY"] = anthropic_config["api_key"]
            model_name = anthropic_config.get("model", "claude-3-opus-20240229")
            api_base_url = anthropic_config.get("api_base_url")
            
            self.llm_params = {"model": model_name}
            if api_base_url:
                self.llm_params["api_base_url"] = api_base_url
            
            # Initialize vector stores
            self.vector_stores = {
                "main": get_vector_store(self.config, store_type="main"),
                "entity": get_vector_store(self.config, store_type="entity"),
                "community": get_vector_store(self.config, store_type="community")
            }
            
            # Configure embedding model
            embedding_config = self.config.get("embedding_model", {})
            embed_model_name = embedding_config.get("name", "intfloat/multilingual-e5-small")
            embed_model = HuggingFaceEmbedding(model_name=embed_model_name)
            
            # Configure chunking
            chunking_config = self.config.get("chunking", {})
            chunk_size = chunking_config.get("chunk_size", 1024)
            chunk_overlap = chunking_config.get("chunk_overlap", 20)
            node_parser = SentenceSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
            
            # Configure Settings
            llm = Anthropic(**self.llm_params)
            Settings.llm = llm
            Settings.embed_model = embed_model
            Settings.node_parser = node_parser
            
            # Initialize file filter
            ignore_patterns = self.config.get("ignore_patterns", [])
            self.file_filter = FileFilter(ignore_patterns)
            
            self.is_initialized = True
            logger.info("Configuration initialized successfully")
            return "âœ… è¨­å®šãŒæ­£å¸¸ã«èª­ã¿è¾¼ã¾ã‚Œã¾ã—ãŸ"
            
        except Exception as e:
            error_msg = f"âŒ è¨­å®šã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"
            logger.error(error_msg)
            return error_msg
    
    def add_documents_sync(self, input_dir: str, output_dir: str, progress=gr.Progress()) -> str:
        if not self.is_initialized:
            return "âŒ è¨­å®šãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã¾ãšè¨­å®šã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚"
        
        if not input_dir or not output_dir:
            return "âŒ å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¨å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚"
        
        try:
            progress(0, desc="ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‡¦ç†ã‚’é–‹å§‹...")
            logger.info(f"Adding documents: input_dir={input_dir}, output_dir={output_dir}")
            
            community_detection_config = self.config.get("community_detection", {})
            
            progress(0.5, desc="ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‡¦ç†ä¸­...")
            add_documents(
                input_dir,
                output_dir,
                self.vector_stores["main"],
                self.vector_stores["entity"],
                self.vector_stores["community"],
                community_detection_config,
                True,  # use_archive_reader
                self.file_filter
            )
            
            progress(1.0, desc="å®Œäº†")
            result = f"âœ… ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒæ­£å¸¸ã«è¿½åŠ ã•ã‚Œã¾ã—ãŸ\nå…¥åŠ›: {input_dir}\nå‡ºåŠ›: {output_dir}"
            logger.info("Documents added successfully")
            return result
            
        except Exception as e:
            error_msg = f"âŒ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¿½åŠ ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"
            logger.error(error_msg)
            return error_msg
    
    def search_chat(self, message: str, history: list, search_method: str, output_dir: str, progress=gr.Progress()) -> tuple:
        if not self.is_initialized:
            error_msg = "âŒ è¨­å®šãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã¾ãšè¨­å®šã‚¿ãƒ–ã§è¨­å®šã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚"
            history.append([message, error_msg])
            return "", history
        
        if not message.strip():
            error_msg = "âŒ æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
            history.append([message, error_msg])
            return "", history
        
        if not output_dir:
            error_msg = "âŒ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚"
            history.append([message, error_msg])
            return "", history
        
        try:
            progress(0, desc="æ¤œç´¢ã‚’é–‹å§‹...")
            logger.info(f"Searching: query='{message}', search_method={search_method}")
            
            progress(0.5, desc="æ¤œç´¢ä¸­...")
            result = search_index(
                message,
                output_dir,
                self.llm_params,
                self.vector_stores["main"],
                self.vector_stores["entity"],
                self.vector_stores["community"],
                search_method
            )
            
            progress(1.0, desc="å®Œäº†")
            logger.info("Search completed successfully")
            
            # Format the response for chat - Anthropic Claude style
            response = f"ğŸ” **æ¤œç´¢æ–¹æ³•**: {self._get_search_method_name(search_method)}\n\n{result}"
            history.append([message, response])
            
            return "", history
            
        except Exception as e:
            error_msg = f"âŒ æ¤œç´¢ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"
            logger.error(error_msg)
            history.append([message, error_msg])
            return "", history
    
    def _get_search_method_name(self, search_method: str) -> str:
        method_names = {
            "both": "çµ±åˆæ¤œç´¢ï¼ˆã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ + ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ï¼‰",
            "main": "ãƒ¡ã‚¤ãƒ³æ¤œç´¢ï¼ˆåŸºæœ¬çš„ãªæ„å‘³æ¤œç´¢ï¼‰",
            "entity": "ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æ¤œç´¢ï¼ˆå›ºæœ‰åè©ãƒ»æ¦‚å¿µä¸­å¿ƒï¼‰",
            "community": "ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ¤œç´¢ï¼ˆé–¢é€£æ€§ãƒ»ã‚°ãƒ«ãƒ¼ãƒ—ä¸­å¿ƒï¼‰"
        }
        return method_names.get(search_method, search_method)

# Global app instance
app = GraphRAGApp()

def create_interface():
    with gr.Blocks(title="GraphRAG Anthropic LlamaIndex", theme=gr.themes.Soft()) as interface:
        gr.Markdown("# ğŸ”— GraphRAG Anthropic LlamaIndex Web App")
        gr.Markdown("CLIãƒ„ãƒ¼ãƒ«ã®ãŸã‚ã®ã‚·ãƒ³ãƒ—ãƒ«ãªWebã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹")
        
        with gr.Tab("âš™ï¸ è¨­å®š"):
            gr.Markdown("### è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿")
            config_path = gr.Textbox(
                label="è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹",
                value="config.yaml",
                placeholder="config.yamlãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’å…¥åŠ›"
            )
            config_btn = gr.Button("è¨­å®šã‚’èª­ã¿è¾¼ã¿", variant="primary")
            config_status = gr.Textbox(
                label="è¨­å®šçŠ¶æ³",
                interactive=False,
                lines=3
            )
            
            config_btn.click(
                fn=app.initialize_config,
                inputs=[config_path],
                outputs=[config_status]
            )
        
        with gr.Tab("ğŸ“„ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¿½åŠ "):
            gr.Markdown("### ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«è¿½åŠ ")
            
            with gr.Row():
                input_dir = gr.Textbox(
                    label="å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª",
                    value="./data",
                    placeholder="ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒæ ¼ç´ã•ã‚Œã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª"
                )
                output_dir = gr.Textbox(
                    label="å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª",
                    value="./graphrag_output",
                    placeholder="å‡¦ç†çµæœã®å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª"
                )
            
            add_btn = gr.Button("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è¿½åŠ ", variant="primary")
            add_result = gr.Textbox(
                label="å‡¦ç†çµæœ",
                interactive=False,
                lines=5
            )
            
            add_btn.click(
                fn=app.add_documents_sync,
                inputs=[input_dir, output_dir],
                outputs=[add_result]
            )
        
        with gr.Tab("ğŸ” æ¤œç´¢"):
            gr.Markdown("### ğŸ’¬ ãƒãƒ£ãƒƒãƒˆå½¢å¼ã§æ¤œç´¢")
            
            with gr.Row():
                with gr.Column(scale=3):
                    search_output_dir = gr.Textbox(
                        label="å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª",
                        value="./graphrag_output",
                        placeholder="ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒæ ¼ç´ã•ã‚Œã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª"
                    )
                with gr.Column(scale=2):
                    search_method = gr.Dropdown(
                        label="æ¤œç´¢æ–¹æ³•",
                        choices=[
                            ("çµ±åˆæ¤œç´¢ï¼ˆæ¨å¥¨ï¼‰", "both"),
                            ("ãƒ¡ã‚¤ãƒ³æ¤œç´¢", "main"), 
                            ("ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æ¤œç´¢", "entity"),
                            ("ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ¤œç´¢", "community")
                        ],
                        value="both",
                        info="æ¤œç´¢ã®æ–¹æ³•ã‚’é¸æŠã—ã¦ãã ã•ã„"
                    )
            
            # Chat interface
            chatbot = gr.Chatbot(
                value=[],
                label="æ¤œç´¢ãƒãƒ£ãƒƒãƒˆ",
                show_label=True,
                height=400,
                show_copy_button=True
            )
            
            with gr.Row():
                msg = gr.Textbox(
                    label="ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸",
                    placeholder="è³ªå•ã‚„æ¤œç´¢ã—ãŸã„å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„...",
                    lines=2,
                    scale=4
                )
                send_btn = gr.Button("é€ä¿¡", variant="primary", scale=1)
            
            # Clear chat button
            clear_btn = gr.Button("ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢", variant="secondary")
            
            # Event handlers
            def send_message(message, history, method, output_dir):
                return app.search_chat(message, history, method, output_dir)
            
            def clear_chat():
                return []
            
            # Send message on button click or Enter
            send_btn.click(
                fn=send_message,
                inputs=[msg, chatbot, search_method, search_output_dir],
                outputs=[msg, chatbot]
            )
            
            msg.submit(
                fn=send_message,
                inputs=[msg, chatbot, search_method, search_output_dir],
                outputs=[msg, chatbot]
            )
            
            # Clear chat
            clear_btn.click(
                fn=clear_chat,
                outputs=[chatbot]
            )
        
        with gr.Tab("â„¹ï¸ ä½¿ç”¨æ–¹æ³•"):
            gr.Markdown("""
            ## ğŸ“– ä½¿ç”¨æ‰‹é †
            
            1. **è¨­å®šã‚¿ãƒ–**: ã¾ãšè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆconfig.yamlï¼‰ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„
            2. **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¿½åŠ ã‚¿ãƒ–**: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«è¿½åŠ ã—ã¾ã™
            3. **æ¤œç´¢ã‚¿ãƒ–**: ãƒãƒ£ãƒƒãƒˆå½¢å¼ã§è¿½åŠ ã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰æ¤œç´¢ã‚’å®Ÿè¡Œã—ã¾ã™
            
            ## ğŸ” æ¤œç´¢æ–¹æ³•ã®èª¬æ˜
            
            - **çµ±åˆæ¤œç´¢ï¼ˆæ¨å¥¨ï¼‰**: ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã¨ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ¤œç´¢ã‚’çµ„ã¿åˆã‚ã›ãŸç·åˆçš„ãªæ¤œç´¢
            - **ãƒ¡ã‚¤ãƒ³æ¤œç´¢**: åŸºæœ¬çš„ãªæ„å‘³æ¤œç´¢ï¼ˆå˜èªã®é¡ä¼¼æ€§ãƒ™ãƒ¼ã‚¹ï¼‰
            - **ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æ¤œç´¢**: å›ºæœ‰åè©ã‚„é‡è¦ãªæ¦‚å¿µã«ç„¦ç‚¹ã‚’å½“ã¦ãŸæ¤œç´¢
            - **ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ¤œç´¢**: é–¢é€£æ€§ã®é«˜ã„ãƒˆãƒ”ãƒƒã‚¯ã‚°ãƒ«ãƒ¼ãƒ—ã‹ã‚‰æ¤œç´¢
            
            ## ğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 
            
            ```
            ./data/              # å…¥åŠ›ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
            ./graphrag_output/   # å‡¦ç†çµæœãƒ»ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            config.yaml          # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
            ```
            
            ## âš™ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä¾‹
            
            ```yaml
            anthropic:
              api_key: "your-api-key"
              model: "claude-3-opus-20240229"
            
            input_dir: "./data"
            output_dir: "./graphrag_output"
            
            embedding_model:
              name: "intfloat/multilingual-e5-small"
            
            chunking:
              chunk_size: 1024
              chunk_overlap: 20
            
            ignore_patterns:
              - "*.tmp"
              - ".git/*"
            ```
            
            ## ğŸ’¬ ãƒãƒ£ãƒƒãƒˆæ¤œç´¢ã®ä½¿ã„æ–¹
            
            1. æ¤œç´¢æ–¹æ³•ã‚’é¸æŠï¼ˆé€šå¸¸ã¯ã€Œçµ±åˆæ¤œç´¢ã€ãŒãŠã™ã™ã‚ï¼‰
            2. ãƒãƒ£ãƒƒãƒˆæ¬„ã«è‡ªç„¶ãªæ—¥æœ¬èªã§è³ªå•ã‚’å…¥åŠ›
            3. Enterã‚­ãƒ¼ã¾ãŸã¯ã€Œé€ä¿¡ã€ãƒœã‚¿ãƒ³ã§æ¤œç´¢å®Ÿè¡Œ
            4. çµæœãŒãƒãƒ£ãƒƒãƒˆå½¢å¼ã§è¡¨ç¤ºã•ã‚Œã¾ã™
            5. ç¶šã‘ã¦è¿½åŠ ã®è³ªå•ã‚‚å¯èƒ½ã§ã™
            """)
    
    return interface

def main():
    interface = create_interface()
    interface.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True
    )

if __name__ == "__main__":
    main()