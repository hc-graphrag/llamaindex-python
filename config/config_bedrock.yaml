# Configuration for graphrag-anthropic-llamaindex with AWS Bedrock

# LLMプロバイダー選択: AWS Bedrock
llm_provider: "bedrock"

# AWS Bedrock設定
bedrock:
  model: "anthropic.claude-3-sonnet-20240229-v1:0"
  region: "us-east-1"

embedding_model:
  name: "intfloat/multilingual-e5-small"

chunking:
  chunk_size: 1024
  chunk_overlap: 20

input_dir: "./data"
output_dir: "./graphrag_output_bedrock"

# Ignore patterns for file processing
ignore_patterns:
  - "*.tmp"
  - "*.log"
  - "*.cache"
  - "*.bak"
  - "*.swp"
  - "*.DS_Store"
  - "Thumbs.db"
  - ".git/*"
  - ".gitignore"
  - "__pycache__/*"
  - "*.pyc"
  - "node_modules/*"
  - ".env"
  - ".env.*"

# Vector Store Configuration
# All vector stores are consolidated into a single LanceDB database
# with different tables (hardcoded) for each store type:
# - main: "vectors" table
# - entity: "entities_vectors" table
# - community: "community_vectors" table
vector_store:
  type: "lancedb"
  lancedb:
    uri: "lancedb" # Single consolidated database for all stores

community_detection:
  max_cluster_size: 10
  use_lcc: True
  seed: 42